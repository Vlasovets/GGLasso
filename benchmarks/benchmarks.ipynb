{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import datetime\n",
    "\n",
    "from sklearn.covariance import GraphicalLasso as sk_GL\n",
    "from sklearn.covariance import empirical_covariance\n",
    "from sklearn import set_config\n",
    "set_config(print_changed_only=False)\n",
    "\n",
    "from gglasso.solver.single_admm_solver import ADMM_SGL\n",
    "from gglasso.solver.single_admm_solver import block_SGL\n",
    "from gglasso.helper.data_generation import time_varying_power_network, group_power_network, sample_covariance_matrix\n",
    "from gglasso.helper.model_selection import single_grid_search\n",
    "from benchmarks import models_to_dict, sklearn_time_benchmark, admm_time_benchmark, model_solution, benchmark_parameters, plot_log_distance\n",
    "from benchmarks import network_generation, hamming_distance, sparsity_benchmark, time_benchmark, dict_to_dataframe, dict_shape\n",
    "\n",
    "from regain.covariance import GraphicalLasso as rg_GL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_dict=dict()\n",
    "X_dict=dict()\n",
    "Theta_dict=dict()\n",
    "\n",
    "p_list=[100, 300, 1000]\n",
    "N_list=[300, 600, 2000]\n",
    "\n",
    "for p, N in zip(p_list, N_list):\n",
    "    S, X, Theta = network_generation(p, N, K=1, M=2)\n",
    "    \n",
    "    S_dict[p, N] = S\n",
    "    X_dict[p, N] = X\n",
    "    Theta_dict[p, N] = Theta\n",
    "\n",
    "print(\"\\n Shape of S_i:\", dict_shape(S_dict))\n",
    "print(\"\\n Shape of X_i:\", dict_shape(X_dict))\n",
    "print(\"\\n Shape of Theta_i:\", dict_shape(Theta_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_params, rg_params, admm_params = benchmark_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-belief",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_tol_list = [0.8, 0.5, 0.25, 0.1]\n",
    "enet_list = [0.5, 0.25, 0.1]\n",
    "X_1 = list(X_dict.values())[0]\n",
    "sk_params = {\"tol\": sk_tol_list, \"enet\": enet_list}\n",
    "models = models_to_dict(models=[\"sklearn\"], lambda1=0.1, max_iter=50000, sk_params=sk_params)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sk_GL(alpha=0.1, max_iter=50000, tol=1e-8, enet_tol=0.01, assume_centered=True).fit(X_1)\n",
    "Z_prec = Z.precision_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, ac, Z_sk = sklearn_time_benchmark(models=models, X=X_1, Z=Z_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = sparsity_benchmark(Theta_dict=Theta_dict, Z_dict=Z_sk, t_rounding=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'name': t.keys(), 'time': t.values(), \"accuracy\": ac.values(), \"hamming\": sparsity.values()})\n",
    "df['split'] = df['name'].str.split('_')\n",
    "columns_names = [\"method\", \"tol_str\", \"tol\", \"rtol_str\", \"rtol\"]\n",
    "df[columns_names] = pd.DataFrame(df['split'].tolist(), index=df['split'].index)\n",
    "\n",
    "redundant_cols = ['split', \"tol_str\", \"rtol_str\"]\n",
    "df = df.drop(redundant_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x=\"time\", y=\"accuracy\", text = \"tol\", color= \"method\", \n",
    "              log_y = True,\n",
    "              labels={\n",
    "                     \"time\": \"Time, s\",\n",
    "                     \"accuracy\": \"Log_distance\",\n",
    "                     \"method\": \"method\"\n",
    "                 },\n",
    "              template = \"plotly_white\",\n",
    "              title=\"Log-distance between Z and Z' with respect to ADMM convergence rates\")\n",
    "fig.update_traces(mode='markers+lines')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-candle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = dict()\n",
    "accuracy_dict = dict()\n",
    "Z_dict = dict()\n",
    "\n",
    "for X, S in zip(list(X_dict.values()), list(S_dict.values())):\n",
    "    times, accs, precs = time_benchmark(X=X, S=S, Z_model=\"sklearn\", lambda1=0.1, n_iter=5,\n",
    "                                        sk_params=sk_params, rg_params=rg_params, admm_params=admm_params)\n",
    "    \n",
    "    time_dict.update(times)\n",
    "    accuracy_dict.update(accs)\n",
    "    Z_dict.update(precs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = sparsity_benchmark(Theta_dict=Theta_dict, Z_dict=Z_dict, t_rounding=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dict_to_dataframe(times=time_dict, acc_dict=accuracy_dict, spars_dict=sparsity)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_log_distance(df, upper_bound=0.01, lower_bound=0.001)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df[(df[\"accuracy\"] < 0.01) & (df[\"accuracy\"] > 0.001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = dict()\n",
    "frames = dict()\n",
    "for p in b[\"p\"].unique():\n",
    "    for method in b[\"method\"].unique():\n",
    "        names[method] = b[(b[\"p\"] == p) & (b[\"method\"] == method)][\"hamming\"].min()\n",
    "    frame = pd.DataFrame(names.items(), columns=['method', 'min_hamming'])\n",
    "    frame = frame.sort_values(by='min_hamming', ascending=True)\n",
    "    frames[p] = frame.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[1000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}