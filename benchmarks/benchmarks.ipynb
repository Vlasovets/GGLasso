{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.pardir)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import itertools\n",
    "from itertools import product\n",
    "\n",
    "from regain.covariance import GraphicalLasso as rg_GL\n",
    "from regain import datasets, utils\n",
    "\n",
    "from sklearn.covariance import GraphicalLasso as sk_GL\n",
    "from sklearn import set_config\n",
    "\n",
    "from regain_benchmark import regain_time\n",
    "from sklearn_benchmark import sklearn_time\n",
    "from gglasso_benchmark import gglasso, gglasso_time\n",
    "\n",
    "from utilita import network_generation, model_solution, benchmark_parameters \n",
    "from utilita import sparsity_benchmark, dict_shape, hamming_dict\n",
    "from utilita import benchmarks_dataframe, best_time_dataframe, drop_acc_duplicates\n",
    "\n",
    "from plots import plot_accuracy, plot_scalability, plot_lambdas\n",
    "\n",
    "from tqdm.contrib import tzip\n",
    "from tqdm.contrib.itertools import product\n",
    "\n",
    "set_config(print_changed_only=False)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-synthetic",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-revolution",
   "metadata": {},
   "source": [
    "### Power networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_dict=dict()\n",
    "X_dict=dict()\n",
    "Theta_dict=dict()\n",
    "\n",
    "# p_list=[100, 500, 1000, 2000]\n",
    "# N_list=[200, 1000, 2000, 4000]\n",
    "p_list=[500, 1000]\n",
    "N_list=[1000, 2000]\n",
    "\n",
    "print(\" Power network generation \".center(40, '-'))\n",
    "\n",
    "for p, N in tzip(p_list, N_list):\n",
    "    start = time.perf_counter()\n",
    "    S, X, Theta = network_generation(p, N, M=10)\n",
    "    end = time.perf_counter()\n",
    "    print(\"p: %5d, N : %5d, Time : %5.4f\" % (p, N, end-start))\n",
    "\n",
    "    S_dict[p, N] = S\n",
    "    X_dict[p, N] = X\n",
    "    Theta_dict[p, N] = Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Shape of S_i:\", dict_shape(S_dict))\n",
    "print(\"\\n Shape of X_i:\", dict_shape(X_dict))\n",
    "print(\"\\n Shape of Theta_i:\", dict_shape(Theta_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-homework",
   "metadata": {},
   "source": [
    "### Latent variables data from <em>regain</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "n_times = [20, 50, 100]\n",
    "n_dims = np.sqrt(np.logspace(2, 5, 10)).astype(int)\n",
    "\n",
    "n_samples = 200\n",
    "n_dim_lat = 2\n",
    "\n",
    "np.random.seed(42)\n",
    "with utils.suppress_stdout():\n",
    "    data = {\n",
    "        (dim, T): datasets.make_dataset(\n",
    "            mode='ma', n_samples=n_samples, \n",
    "            n_dim_lat=n_dim_lat, n_dim_obs=dim,\n",
    "            T=T, epsilon=1e-2)\n",
    "        for dim, T in (product(n_dims, n_times))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lat = dict()\n",
    "\n",
    "for key in data.keys():\n",
    "    X_lat.update({key:data[key]['data']})\n",
    "    \n",
    "X_lat = list(X_lat.values())\n",
    "X_lat = [x for data in X_lat for x in data] #flatten data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_lat = list() # empirical covariance matrices\n",
    "for i in X_lat:\n",
    "    S_lat.append(np.cov(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-oliver",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_params, rg_params, gglasso_params, lambda_list = benchmark_parameters(enet_list=[0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-presentation",
   "metadata": {},
   "source": [
    "### Model solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_time_dict = dict()\n",
    "model_Z_dict = dict()\n",
    "\n",
    "for X, l1 in product(list(X_dict.values()), lambda_list):\n",
    "    model = \"sklearn\"\n",
    "    Z, Z_time, info = model_solution(model=model, X=X, lambda1=l1)\n",
    "    \n",
    "    key = \"p_\" + str(X.shape[1]) + \"_l1_\" + str(l1)\n",
    "    model_time_dict.update({key: Z_time})\n",
    "    model_Z_dict.update({key: Z})\n",
    "print(\"Model solution({0}): {1}\".format(model,info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-candle",
   "metadata": {},
   "source": [
    "### GGLasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = dict()\n",
    "accuracy_dict = dict()\n",
    "Z_dict = dict()\n",
    "trace_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, S in tzip(list(X_dict.values()), list(S_dict.values())):\n",
    "    Omega_0 = np.eye(len(S))\n",
    "    gg_time, gg_accuracy, Z_gg = gglasso_time(S=S, Omega_0=Omega_0, Z=model_Z_dict, lambda_list=lambda_list,\n",
    "                                              n_iter=1 + 1, gglasso_params=gglasso_params)\n",
    "    time_dict.update(gg_time)\n",
    "    accuracy_dict.update(gg_accuracy)\n",
    "    Z_dict.update(Z_gg)\n",
    "\n",
    "    for key, item in Z_gg.items():\n",
    "        trace_dict.update({key: {\"Z\": item, \"X\": X, \"S\": S,\"l1\": l1}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-sally",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-diving",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for X, S in tzip(list(X_dict.values()), list(S_dict.values())):\n",
    "    sk_time, sk_accuracy, Z_sk = sklearn_time(X=X, Z=model_Z_dict, sk_params=sk_params, lambda_list=lambda_list, n_iter=2)\n",
    "    \n",
    "    time_dict.update(sk_time)\n",
    "    accuracy_dict.update(sk_accuracy)\n",
    "    Z_dict.update(Z_sk)\n",
    "    \n",
    "    for key, item in Z_sk.items():\n",
    "        trace_dict.update({key: {\"Z\": item, \"X\": X, \"S\": S,\"l1\": l1}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-illness",
   "metadata": {},
   "source": [
    "### Regain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, S in tzip(list(X_dict.values()), list(S_dict.values())):\n",
    "    rg_time, rg_accuracy, Z_rg = regain_time(X=X, Z=model_Z_dict, rg_params=rg_params, lambda_list=lambda_list, n_iter=2)\n",
    "    \n",
    "    time_dict.update(rg_time)\n",
    "    accuracy_dict.update(rg_accuracy)\n",
    "    Z_dict.update(Z_rg)\n",
    "    \n",
    "    for key, item in Z_rg.items():\n",
    "        trace_dict.update({key: {\"Z\": item, \"X\": X, \"S\": S,\"l1\": l1}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-maine",
   "metadata": {},
   "source": [
    "### Import benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# obj = pd.read_pickle(r'sklearn_acc_dict.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-preparation",
   "metadata": {},
   "source": [
    "### Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = hamming_dict(Theta_dict=Theta_dict, Z_dict=Z_dict, t_rounding=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-rough",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmarks_dataframe(times=dict, acc_dict=dict, spars_dict=dict):\n",
    "    \"\"\"\n",
    "    Turn benchmark dictionaries into dataframes.\n",
    "    :param times: dict\n",
    "    Input dictionary where 'key' is the model and 'value' is its runtime.\n",
    "    :param acc_dict: dict\n",
    "    Input dictionary where 'key' is a model and 'value' is its corresponding accuracy given as:\n",
    "    np.linalg.norm(Z - np.array(Z_i)) / np.linalg.norm(Z)\n",
    "    where Z is our model solution and Z_i is the model.\n",
    "    :param spars_dict: dict\n",
    "    Input dictionary where 'key' is a model and 'value' is its corresponding sparsity measured by\n",
    "    Hamming distance.\n",
    "    :return: Pandas.DataFrame()\n",
    "    \"\"\"\n",
    "    assert len(times) == len(acc_dict) == len(spars_dict)\n",
    "\n",
    "    # The time measured during the grid search of best hyperparameters for the models\n",
    "    df = pd.DataFrame(data={'name': list(times.keys()),\n",
    "                            'time': list(times.values()),\n",
    "                            \"accuracy\": list(acc_dict.values())})\n",
    "\n",
    "    df['split'] = df['name'].str.split('_')\n",
    "    columns_names = [\"method\", \"tol_str\", \"tol\", \"rtol_str\", \"rtol\", \"p_str\", \"p\", \"l1_str\", \"l1\"]\n",
    "    df[columns_names] = pd.DataFrame(df['split'].tolist(), index=df['split'].index)\n",
    "\n",
    "    redundant_cols = ['split', \"tol_str\", \"rtol_str\", \"p_str\", \"l1_str\"]\n",
    "    df = df.drop(redundant_cols, axis=1)\n",
    "\n",
    "    convert_dict = {'tol': float, 'rtol': float, \"p\": int, \"l1\": float}\n",
    "    df = df.astype(convert_dict)\n",
    "    df['method_str'] = df['method'].str.replace('\\d+', '')\n",
    "\n",
    "    df_dist = pd.DataFrame(data={'name': list(spars_dict.keys()),\n",
    "                                 \"hamming\": list(spars_dict.values())})\n",
    "\n",
    "    df_dist['name'] = df_dist['name'].str.replace('precision_', '')\n",
    "\n",
    "    final = pd.merge(df, df_dist, how='inner', on='name')\n",
    "\n",
    "    final = final.sort_values(by=['time'])\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = benchmarks_dataframe(times=time_dict, acc_dict=accuracy_dict, spars_dict=sparsity)\n",
    "df = drop_acc_duplicates(df)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_lambdas(df, upper_bound=0.01, lower_bound=0.000001)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_accuracy(df, upper_bound=0.1, lower_bound=0.0000001, lambda_filter=0.05)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = sparsity_benchmark(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[1000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
