{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "from regain_benchmark import regain_time\n",
    "from sklearn_benchmark import sklearn_time\n",
    "from gglasso_benchmark import gglasso_time\n",
    "\n",
    "from utilita import network_generation, model_solution, benchmark_parameters \n",
    "from utilita import sparsity_benchmark, dict_shape, calc_hamming_dict\n",
    "\n",
    "from plots import plot_accuracy, plot_scalability, plot_lambdas\n",
    "\n",
    "from tqdm.contrib import tzip\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-synthetic",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-revolution",
   "metadata": {},
   "source": [
    "### Power networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_dict=dict()\n",
    "X_dict=dict()\n",
    "Theta_dict=dict()\n",
    "\n",
    "p_list=[100, 200, 500]\n",
    "N_list=[200, 300, 600]\n",
    "\n",
    "print(\" Network generation \".center(40, '-'))\n",
    "\n",
    "for p, N in tzip(p_list, N_list):\n",
    "    S, X, Theta = network_generation(p, N, M=10)\n",
    "    print(\"p: %5d, N : %5d\" % (p, N))\n",
    "\n",
    "    S_dict[p, N] = S.copy()\n",
    "    X_dict[p, N] = X.copy()\n",
    "    Theta_dict[p, N] = Theta.copy()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Shape of S_i:\", dict_shape(S_dict))\n",
    "print(\"\\n Shape of X_i:\", dict_shape(X_dict))\n",
    "print(\"\\n Shape of Theta_i:\", dict_shape(Theta_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-homework",
   "metadata": {},
   "source": [
    "### Latent variables data from <em>regain</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from regain import datasets, utils\n",
    "\n",
    "# n_times = [20, 50, 100]\n",
    "# n_dims = np.sqrt(np.logspace(2, 5, 10)).astype(int)\n",
    "\n",
    "# n_samples = 200\n",
    "# n_dim_lat = 2\n",
    "\n",
    "# np.random.seed(42)\n",
    "# with utils.suppress_stdout():\n",
    "#     data = {\n",
    "#         (dim, T): datasets.make_dataset(\n",
    "#             mode='ma', n_samples=n_samples, \n",
    "#             n_dim_lat=n_dim_lat, n_dim_obs=dim,\n",
    "#             T=T, epsilon=1e-2)\n",
    "#         for dim, T in (product(n_dims, n_times))\n",
    "#     }\n",
    "    \n",
    "    \n",
    "# X_lat = dict()\n",
    "\n",
    "# for key in data.keys():\n",
    "#     X_lat.update({key:data[key]['data']})\n",
    "    \n",
    "# X_lat = list(X_lat.values())\n",
    "# X_lat = [x for data in X_lat for x in data] #flatten data array\n",
    "\n",
    "# S_lat = list() # empirical covariance matrices\n",
    "# for i in X_lat:\n",
    "#     S_lat.append(np.cov(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-oliver",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_list = [0.5, 0.1, 0.05]\n",
    "sk_params, rg_params, gglasso_params, lambda_list = benchmark_parameters(lambda_list = lambda_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-presentation",
   "metadata": {},
   "source": [
    "### Model solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_time_dict = dict()\n",
    "model_Z_dict = dict()\n",
    "reference_solver = \"regain\"\n",
    "\n",
    "print(f\"Solving for a reference solution with solver {reference_solver}:\")\n",
    "\n",
    "for X, l1 in product(list(X_dict.values()), lambda_list):\n",
    "    \n",
    "    Z, Z_time, info = model_solution(solver=reference_solver, X=X, lambda1=l1)\n",
    "    \n",
    "    key = \"p_\" + str(X.shape[1]) + \"_N_\" + str(X.shape[0]) + \"_l1_\" + str(l1)\n",
    "    model_time_dict.update({key: Z_time})\n",
    "    model_Z_dict.update({key: Z})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = dict()\n",
    "accuracy_dict = dict()\n",
    "Z_dict = dict()\n",
    "\n",
    "n_iter = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-candle",
   "metadata": {},
   "source": [
    "### GGLasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, S in tzip(list(X_dict.values()), list(S_dict.values())):\n",
    "    Omega_0 = np.eye(len(S))\n",
    "    gg_time, gg_accuracy, Z_gg = gglasso_time(S=S, X=X, Omega_0=Omega_0, Z=model_Z_dict, lambda_list=lambda_list,\n",
    "                                              n_iter=n_iter, gglasso_params=gglasso_params, warm_start=False)\n",
    "    \n",
    "    time_dict.update(gg_time)\n",
    "    accuracy_dict.update(gg_accuracy)\n",
    "    Z_dict.update(Z_gg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-sally",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-diving",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for X, S in tzip(list(X_dict.values()), list(S_dict.values())):\n",
    "    sk_time, sk_accuracy, Z_sk = sklearn_time(X=X, Z=model_Z_dict, sk_params=sk_params, lambda_list=lambda_list, \\\n",
    "                                              n_iter=n_iter)\n",
    "    \n",
    "    time_dict.update(sk_time)\n",
    "    accuracy_dict.update(sk_accuracy)\n",
    "    Z_dict.update(Z_sk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-illness",
   "metadata": {},
   "source": [
    "### Regain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, S in tzip(list(X_dict.values()), list(S_dict.values())):\n",
    "    rg_time, rg_accuracy, Z_rg = regain_time(X=X, Z=model_Z_dict, rg_params=rg_params, lambda_list=lambda_list, \\\n",
    "                                             n_iter=n_iter, warm_start=False)\n",
    "    \n",
    "    time_dict.update(rg_time)\n",
    "    accuracy_dict.update(rg_accuracy)\n",
    "    Z_dict.update(Z_rg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-preparation",
   "metadata": {},
   "source": [
    "### Hamming distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_dict = calc_hamming_dict(Theta_dict=Theta_dict, Z_dict=Z_dict, t_rounding=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-rough",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmarks_dataframe(times=dict, acc=dict, hamming=dict):\n",
    "    \"\"\"\n",
    "    Turn benchmark dictionaries into dataframes.\n",
    "    :param times: dict\n",
    "    Input dictionary where 'key' is the model and 'value' is its runtime.\n",
    "    :param acc_dict: dict\n",
    "    Input dictionary where 'key' is a model and 'value' is its corresponding accuracy given as:\n",
    "    np.linalg.norm(Z - np.array(Z_i)) / np.linalg.norm(Z)\n",
    "    where Z is our model solution and Z_i is the model.\n",
    "    :param spars_dict: dict\n",
    "    Input dictionary where 'key' is a model and 'value' is its corresponding Hamming distance to the oracle precision matrix.\n",
    "    :return: Pandas.DataFrame()\n",
    "    \"\"\"\n",
    "    assert len(times) == len(acc) == len(hamming)\n",
    "\n",
    "    all_dict = dict()\n",
    "    for key in times.keys():\n",
    "        all_dict[key] = {'time': times[key], 'accuracy': acc[key], 'hamming': hamming[key]}\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(all_dict, orient = 'index')\n",
    "    \n",
    "    # split key into columns\n",
    "    df['split'] = df.index.str.split('_')\n",
    "    columns_names = [\"method\", \"tol_str\", \"tol\", \"rtol_str\", \"rtol\", \"p_str\", \"p\", \"N_str\", \"N\", \"l1_str\", \"l1\"]\n",
    "    df[columns_names] = pd.DataFrame(df['split'].tolist(), index=df['split'].index)\n",
    "    \n",
    "    redundant_cols = ['split', \"tol_str\", \"rtol_str\", \"p_str\", \"N_str\", \"l1_str\"]\n",
    "    df = df.drop(redundant_cols, axis=1)\n",
    "    \n",
    "    convert_dict = {'tol': float, 'rtol': float, \"p\": int, \"N\": int, \"l1\": float}\n",
    "    df = df.astype(convert_dict)\n",
    "    df = df.sort_values(['p', 'l1', 'method', 'time'])\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = benchmarks_dataframe(times=time_dict, acc=accuracy_dict, hamming=hamming_dict)\n",
    "\n",
    "#df = df.reset_index(drop=True)\n",
    "df[df.p==500][df.l1==0.05].sort_values('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bm(df, lambda_list, min_acc = 1e-2, log_scale = True):\n",
    "    \n",
    "    fig, axs = plt.subplots(len(lambda_list), 1, figsize = (5,8))\n",
    "    j = 0\n",
    "    for l1 in lambda_list:\n",
    "        ax = axs[j]\n",
    "        df_sub = df[(df.l1 == l1) & (df.accuracy <= min_acc)]\n",
    "        tmp = df_sub.groupby([\"p\", \"N\", \"method\"])[\"time\"].min()\n",
    "        \n",
    "        tmp.unstack().plot(ls = '-', marker = 'o', xlabel = \"(p,N)\", ylabel = \"runtime [sec]\", ax = ax)\n",
    "        ax.set_title(rf\"$\\lambda_1$ = {l1}\")\n",
    "        ax.grid(linestyle = '--')\n",
    "        if log_scale:\n",
    "            ax.set_yscale('log')\n",
    "            #ax.set_xscale('log')\n",
    "        \n",
    "        j+=1\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return\n",
    "\n",
    "plot_bm(df, lambda_list, min_acc = 5e-3, log_scale = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_lambdas(df, upper_bound=0.01, lower_bound=0.000001)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_accuracy(df, upper_bound=0.01, lower_bound=0.0000001, lambda_filter=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383fd837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
