{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /Users/oleg.vlasovetc/Public/GGLasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import datetime\n",
    "from tqdm import trange\n",
    "\n",
    "from sklearn.covariance import GraphicalLasso as sk_GL\n",
    "from sklearn.covariance import empirical_covariance\n",
    "from sklearn import set_config\n",
    "set_config(print_changed_only=False)\n",
    "\n",
    "from gglasso.solver.single_admm_solver import ADMM_SGL\n",
    "from gglasso.solver.single_admm_solver import block_SGL\n",
    "from gglasso.helper.data_generation import time_varying_power_network, group_power_network, sample_covariance_matrix\n",
    "from gglasso.helper.model_selection import single_grid_search\n",
    "from benchmarks import models_to_dict, sklearn_time_benchmark, admm_time_benchmark, model_solution, benchmark_parameters\n",
    "from benchmarks import network_generation, hamming_distance, hamming_dict, time_benchmark, dict_to_dataframe, dict_shape\n",
    "from benchmarks import plot_log_distance, drop_duplicates, sparsity_benchmark\n",
    "\n",
    "from regain.covariance import GraphicalLasso as rg_GL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_dict=dict()\n",
    "X_dict=dict()\n",
    "Theta_dict=dict()\n",
    "\n",
    "# p_list=[100, 300, 1000]\n",
    "# N_list=[300, 600, 2000]\n",
    "p_list=[10000]\n",
    "N_list=[20000]\n",
    "\n",
    "for p, N in zip(p_list, N_list):\n",
    "    S, X, Theta = network_generation(p, N, K=1, M=10)\n",
    "    \n",
    "    S_dict[p, N] = S\n",
    "    X_dict[p, N] = X\n",
    "    Theta_dict[p, N] = Theta\n",
    "\n",
    "print(\"\\n Shape of S_i:\", dict_shape(S_dict))\n",
    "print(\"\\n Shape of X_i:\", dict_shape(X_dict))\n",
    "print(\"\\n Shape of Theta_i:\", dict_shape(Theta_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_params, rg_params, admm_params = benchmark_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = dict()\n",
    "accuracy_dict = dict()\n",
    "Z_dict = dict()\n",
    "\n",
    "for X, S in zip(list(X_dict.values()), list(S_dict.values())):\n",
    "    times, accs, precs = time_benchmark(X=X, S=S, Z_model=\"sklearn\", lambda1=0.1, n_iter=5,\n",
    "                                        sk_params=sk_params, rg_params=rg_params, admm_params=admm_params)\n",
    "    \n",
    "    time_dict.update(times)\n",
    "    accuracy_dict.update(accs)\n",
    "    Z_dict.update(precs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = hamming_dict(Theta_dict=Theta_dict, Z_dict=Z_dict, t_rounding=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dict_to_dataframe(times=time_dict, acc_dict=accuracy_dict, spars_dict=sparsity)\n",
    "df = drop_duplicates(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_log_distance(df, upper_bound=0.01, lower_bound=0.0001)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = sparsity_benchmark(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_start = 100\n",
    "p_end = 10000\n",
    "N_start = 200\n",
    "N_end=20000\n",
    "\n",
    "lambda1 = 0.01\n",
    "max_iter=50000\n",
    "tol=1e-4\n",
    "enet=1e-2\n",
    "n_iter = 2\n",
    "rtol = 1e-4\n",
    "\n",
    "\n",
    "time_dict = dict()\n",
    "time_list = []\n",
    "sk_model = sk_GL(alpha=lambda1, max_iter=max_iter, tol=tol, enet_tol=enet, assume_centered=False)\n",
    "rg_model = rg_GL(alpha=lambda1, max_iter=max_iter, tol=tol, rtol=rtol, assume_centered=False)\n",
    "\n",
    "for p, N in zip(range(p_start, p_end, 1000), range(N_start, N_end, 2000)):\n",
    "    try:\n",
    "        start = time.time()\n",
    "        S, X, Theta = network_generation(p, N, K=1, M=10)\n",
    "        end = time.time()\n",
    "        Omega_0 = np.eye(len(S))\n",
    "        \n",
    "        print(\"Power network generation time in seconds: \", end-start)\n",
    "    except:\n",
    "        print(\"power network cannot be generated, increase M\")\n",
    "        break\n",
    "    \n",
    "    #sklearn\n",
    "    try:\n",
    "        time_list.clear()\n",
    "        for _ in trange(n_iter, desc=str(sk_model), leave=True):\n",
    "            sk_start = time.time()\n",
    "            Z_i = sk_model.fit(X)\n",
    "            sk_end = time.time()\n",
    "            \n",
    "            sk_time = sk_end - sk_start\n",
    "            time_list.append(sk_time)\n",
    "\n",
    "        sk_key = \"sklearn_\" + \"p_\" + str(p) + \"_N_\" + str(N)\n",
    "        time_dict[sk_key] = np.mean(time_list)\n",
    "        sk = False\n",
    "    except:\n",
    "        sk = True\n",
    "        print(\"sklearn kernel has died\")\n",
    "    \n",
    "    #regain\n",
    "    try:\n",
    "        time_list.clear()\n",
    "        for _ in trange(n_iter, desc=str(rg_model), leave=True):\n",
    "            rg_start = time.time()\n",
    "            Z_i = rg_model.fit(X)\n",
    "            rg_end = time.time()\n",
    "\n",
    "            rg_time = rg_end - rg_start\n",
    "            time_list.append(rg_time)\n",
    "\n",
    "        rg_key = \"regain_\" + \"p_\" + str(p) + \"_N_\" + str(N)\n",
    "        time_dict[rg_key] = np.mean(time_list)\n",
    "        rg = False\n",
    "    except:\n",
    "        rg = True\n",
    "        print(\"regain kernel has died\")\n",
    "    \n",
    "    #single-admm\n",
    "    try:\n",
    "        time_list.clear()\n",
    "        single_key = \"single-admm_\" + \"p_\" + str(p) + \"_N_\" + str(N)\n",
    "\n",
    "        for _ in trange(n_iter, desc=single_key, leave=True):\n",
    "            single_start = time.time()\n",
    "            Z_i, info = ADMM_SGL(S, lambda1=lambda1, Omega_0=Omega_0, max_iter=max_iter, tol=tol, rtol=rtol, stopping_criterion=\"boyd\")\n",
    "            single_end = time.time()\n",
    "\n",
    "            single_time = single_end - single_start\n",
    "            time_list.append(single_time)\n",
    "\n",
    "        time_dict[single_key] = np.mean(time_list)\n",
    "        single_admm = False\n",
    "    except:\n",
    "        single_admm = True\n",
    "        print(\"single-admm kernel has died\")\n",
    "    \n",
    "    #block-admm\n",
    "    try:\n",
    "        time_list.clear()\n",
    "        block_key = \"block-admm_\" + \"p_\" + str(p) + \"_N_\" + str(N)\n",
    "\n",
    "        for _ in trange(n_iter, desc=block_key, leave=True):\n",
    "            block_start = time.time()\n",
    "            Z_i = block_SGL(S, lambda1=lambda1, Omega_0=Omega_0, max_iter=max_iter, tol=tol, rtol=rtol, stopping_criterion=\"boyd\")\n",
    "            block_end = time.time()\n",
    "\n",
    "            block_time = block_end - block_start\n",
    "            time_list.append(block_time)\n",
    "\n",
    "        time_dict[block_key] = np.mean(time_list)\n",
    "        block_admm = False\n",
    "    except:\n",
    "        block_admm = True\n",
    "        print(\"block-admm kernel has died\")\n",
    "    \n",
    "    if (sk + rg + single_admm + block_admm) == 4:\n",
    "        print(\"all kernels have died\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(time_df, x=\"time\", y=\"p\", text=\"N\", color=\"method\",\n",
    "                     labels={\n",
    "                         \"time\": \"Time, s\",\n",
    "                         \"p\": \"Number of features, p\",\n",
    "                         \"method\": \"method\"\n",
    "                     },\n",
    "                     template=\"plotly_white\",\n",
    "                     title=\"Scalability plot\")\n",
    "\n",
    "fig.update_traces(mode='markers+lines', marker_line_width=1, marker_size=10)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
