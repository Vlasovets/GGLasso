{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.pardir)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from gglasso.solver.single_admm_solver import ADMM_SGL\n",
    "from gglasso.solver.single_admm_solver import block_SGL\n",
    "from gglasso.helper.data_generation import time_varying_power_network, group_power_network, sample_covariance_matrix\n",
    "from gglasso.helper.model_selection import single_grid_search\n",
    "from benchmarks import models_to_dict, sklearn_time_benchmark, admm_time_benchmark, model_solution, benchmark_parameters\n",
    "from benchmarks import time_benchmark, sparsity_benchmark\n",
    "from benchmarks import sk_scaling, single_scaling, block_scaling\n",
    "\n",
    "from plots import plot_accuracy, plot_scalability\n",
    "from utils import network_generation, dict_shape, hamming_dict\n",
    "from utils import benchmarks_dataframe, best_time_dataframe, drop_acc_duplicates\n",
    "\n",
    "from regain.covariance import GraphicalLasso as rg_GL\n",
    "\n",
    "from sklearn.covariance import GraphicalLasso as sk_GL\n",
    "from sklearn import set_config\n",
    "set_config(print_changed_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from regain import utils\n",
    "# from sklearn import datasets\n",
    "# from sklearn.utils import Bunch\n",
    "# from regain.datasets import datasets\n",
    "# from regain.datasets import make_dataset\n",
    "\n",
    "# # prepare data\n",
    "# n_times = [20, 50, 100]\n",
    "# n_dims = np.sqrt(np.logspace(2, 5, 10)).astype(int)\n",
    "\n",
    "# n_samples = 200\n",
    "# n_dim_lat = 2\n",
    "\n",
    "# np.random.seed(42)\n",
    "# with utils.suppress_stdout():\n",
    "#     data = {\n",
    "#         (dim, T): make_dataset(\n",
    "#             mode='ma', n_samples=n_samples, \n",
    "#             n_dim_lat=n_dim_lat, n_dim_obs=dim,\n",
    "#             T=T, epsilon=1e-2)\n",
    "#         for dim, T in (product(n_dims, n_times))\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_dict=dict()\n",
    "X_dict=dict()\n",
    "Theta_dict=dict()\n",
    "\n",
    "# p_list=[100, 500, 1000, 2500, 5000, 10000]\n",
    "# N_list=[200, 1000, 2000, 5000, 10000, 20000]\n",
    "p_list=[100]\n",
    "N_list=[200]\n",
    "\n",
    "print(\" Power network generation \".center(40, '-'))\n",
    "\n",
    "for p, N in zip(p_list, N_list):\n",
    "    try:\n",
    "        start = time.time()\n",
    "        S, X, Theta = network_generation(p, N, K=1, M=2)\n",
    "        end = time.time()\n",
    "        print(\"p: %5d, N : %5d, Time : %5.4f\" % (p, N, end-start))\n",
    "    except:\n",
    "        print(\"Power network cannot be generated\")\n",
    "        print(\"Tip: increase the number of sub-blocks M\")\n",
    "        break\n",
    "\n",
    "    S_dict[p, N] = S\n",
    "    X_dict[p, N] = X\n",
    "    Theta_dict[p, N] = Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Shape of S_i:\", dict_shape(S_dict))\n",
    "print(\"\\n Shape of X_i:\", dict_shape(X_dict))\n",
    "print(\"\\n Shape of Theta_i:\", dict_shape(Theta_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_params, rg_params, admm_params = benchmark_parameters(S_dict=S_dict, sk_tol_list=[0.5], enet_list=[0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-shelter",
   "metadata": {},
   "source": [
    "## Speed benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = dict()\n",
    "accuracy_dict = dict()\n",
    "Z_dict = dict()\n",
    "\n",
    "for X, S in zip(list(X_dict.values()), list(S_dict.values())):\n",
    "    times, accs, precs = time_benchmark(X=X, S=S, Z_model=\"sklearn\", lambda1=0.1, n_iter=5,\n",
    "                                        sk_params=sk_params, rg_params=rg_params, admm_params=admm_params)\n",
    "    \n",
    "    time_dict.update(times)\n",
    "    accuracy_dict.update(accs)\n",
    "    Z_dict.update(precs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = hamming_dict(Theta_dict=Theta_dict, Z_dict=Z_dict, t_rounding=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = benchmarks_dataframe(times=time_dict, acc_dict=accuracy_dict, spars_dict=sparsity)\n",
    "df = drop_acc_duplicates(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_accuracy(df, upper_bound=0.01, lower_bound=0.0001)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop this over p\n",
    "# df_p = df[df.p==100]\n",
    "# accur = 1e-3\n",
    "# res_p = dict()\n",
    "# for method in df_p.method.unique():\n",
    "#     tmp = df_p[(df_p.method == method) & (df_p.accuracy <= accur)]\n",
    "#     res_p[method] = tmp.time.min()\n",
    "# res_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-monitoring",
   "metadata": {},
   "source": [
    "## Sparsity benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = sparsity_benchmark(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-mentor",
   "metadata": {},
   "source": [
    "## Scalability benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda1 = 0.01\n",
    "max_iter= 50000\n",
    "n_iter = 1\n",
    "tol = 1e-10\n",
    "rtol = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_time_dict = dict()\n",
    "sk = False\n",
    "rg = False\n",
    "\n",
    "for X, S in zip(list(X_dict.values()), list(S_dict.values())):\n",
    "    #sklearn models\n",
    "    if sk == False:\n",
    "        sk_model = sk_GL(alpha=lambda1, max_iter=max_iter, assume_centered=False)\n",
    "        sk_list, sk = sk_scaling(X, sk_model, n_iter)\n",
    "    else:\n",
    "        print(\"sklearn kernel has died at p={}\".format(len(X[0])))\n",
    "        \n",
    "    if rg == False:\n",
    "        rg_model = rg_GL(alpha=lambda1, max_iter=max_iter, assume_centered=False, init=np.eye(S.shape[0]))\n",
    "        rg_list, rg = sk_scaling(X, rg_model, n_iter)\n",
    "    else:\n",
    "        print(\"regain kernel has died at p={}\".format(len(X[0])))\n",
    "    \n",
    "    # ADMM models\n",
    "    Omega_0 = np.eye(len(S))\n",
    "    try:\n",
    "        single_list = single_scaling(S, lambda1, Omega_0, max_iter, tol, rtol, n_iter)\n",
    "    except:\n",
    "        print(\"single ADMM kernel has died at p={}\".format(len(X[0])))\n",
    "    try:\n",
    "        block_list = block_scaling(S, lambda1, Omega_0, max_iter, tol, rtol, n_iter)\n",
    "    except:\n",
    "        print(\"block ADMM kernel has died at p={}\".format(len(X[0])))\n",
    "        \n",
    "    key = \"p_\" + str(len(X[0])) + \"_N_\" + str(len(X))\n",
    "    \n",
    "    scale_time_dict[\"sklearn_\" + key] = np.mean(sk_list)\n",
    "    scale_time_dict[\"regain_\" + key] = np.mean(rg_list)\n",
    "    scale_time_dict[\"single-admm_\" + key] = np.mean(single_list)\n",
    "    scale_time_dict[\"block-admm_\" + key] = np.mean(block_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = best_time_dataframe(scale_time_dict)\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_scalability(time_df)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
