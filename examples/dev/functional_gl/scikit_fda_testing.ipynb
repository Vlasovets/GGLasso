{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181091aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "from skfda.datasets import make_gaussian_process\n",
    "from skfda.misc.covariances import Exponential, Gaussian, Brownian\n",
    "from skfda.misc.metrics import l2_distance, l2_norm\n",
    "from skfda.preprocessing.dim_reduction.feature_extraction import FPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a9d57",
   "metadata": {},
   "source": [
    "Idea: create three covariance functions and sample Gaussian processes. Then do FPCA and compute Functional Graphical Lasso. Let the variables be called $v_1$, $v_2$ and $v_3$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_var = 3\n",
    "n_ts = 100\n",
    "n_samples = 10**3\n",
    "\n",
    "# define three variables\n",
    "cov1 = Gaussian(variance=1.0, length_scale=5.0)\n",
    "cov2 = Gaussian(variance=1.0, length_scale=4.0)\n",
    "cov3 = Brownian(variance=0.2)\n",
    "\n",
    "all_cov = [cov1, cov2, cov3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf2b1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot covariance functions\n",
    "_ = cov1.heatmap()\n",
    "_ = cov2.heatmap()\n",
    "_ = cov3.heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb8f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample gaussian processes\n",
    "samples = list()\n",
    "labels = list()\n",
    "\n",
    "for j in np.arange(n_var):\n",
    "\n",
    "    _ds = make_gaussian_process(\n",
    "            n_samples=n_samples,\n",
    "            n_features=n_ts,\n",
    "            start=0.0,\n",
    "            stop=25.0,\n",
    "            cov=all_cov[j],\n",
    "            random_state=20\n",
    "            )\n",
    "    \n",
    "    \n",
    "    _lb = np.array([f'v{j}'] * n_samples)\n",
    "    \n",
    "    samples.append(_ds)\n",
    "    labels.append(_lb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc0362",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot sampled time series\n",
    "\n",
    "colors = ['darkred', 'C1', 'grey']\n",
    "\n",
    "fig, axs = plt.subplots(n_var,1, figsize=(10,12))\n",
    "\n",
    "for j in range(n_var):\n",
    "    ax = axs.ravel()[j]\n",
    "    samples[j].plot(axes=ax, group=labels[j], group_colors={f'v{j}': colors[j]}, alpha=0.3, lw=0.95)\n",
    "    ax.set_title(f'Sampled time series for v{j}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1f674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do FPCA, reconstruct and plot deviation\n",
    "q = 5\n",
    "fig, axs = plt.subplots(n_var, 2, figsize=(20,12))\n",
    "\n",
    "for j in range(n_var):\n",
    "    this_ds = samples[j]\n",
    "    # do FPCA\n",
    "    fpca = FPCA(n_components=q)\n",
    "    fpca.fit(this_ds)\n",
    "    # reconstruct ds from FPCA\n",
    "    recov_ds = fpca.inverse_transform(fpca.transform(this_ds))\n",
    "    \n",
    "    diff = this_ds - recov_ds\n",
    "    \n",
    "    ax = axs[j,0]\n",
    "    recov_ds.plot(axes=ax, group=labels[j], group_colors={f'v{j}': colors[j]}, alpha=0.3, lw=0.95)\n",
    "    ax.set_title(f'FPCA transformed time series for v{j}')\n",
    "    \n",
    "    ax2 = axs[j,1]\n",
    "    diff.plot(axes=ax2, group=labels[j], group_colors={f'v{j}': colors[j]}, alpha=0.3, lw=0.95)\n",
    "    ax2.set_title(f'Recovery error of FPCA for v{j}')\n",
    "    ax2.set_ylim(ax.get_ylim())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedcd202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot error for increasing numper of FPCA components\n",
    "\n",
    "this_ds = samples[0]\n",
    "all_err = list()\n",
    "all_q = range(4,10)\n",
    "\n",
    "for k in range(len(all_q)):\n",
    "    \n",
    "    fpca = FPCA(n_components=all_q[k])\n",
    "    fpca.fit(this_ds)\n",
    "\n",
    "    print(\"Data shape after FPCA transformation: \", fpca.transform(this_ds).shape)\n",
    "    # reconstruct ds from FPCA\n",
    "    recov_ds = fpca.inverse_transform(fpca.transform(this_ds))\n",
    "    this_err = l2_distance(this_ds,recov_ds) / l2_norm(this_ds)\n",
    "\n",
    "    all_err.append(np.median(this_err))\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(all_q, all_err, c='darkgray', lw = 4, marker='p', markersize=9, markeredgecolor='k')\n",
    "plt.xlabel('Number of FPCA components')\n",
    "plt.ylabel('Median l2 error')\n",
    "plt.grid(ls = '-', lw = .5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8399ad0f",
   "metadata": {},
   "source": [
    "## Functional Graphical Lasso\n",
    "\n",
    "Now, do for each variable a FPCA with $n_{comp}$ components. Then, concatenate the FPCA coefficients for each sample and compute correlations. With this, we are ready to compute Functional Graphical Lasso.\n",
    "\n",
    "If we choose $n_{comp}=8$, we expect $3\\cdot8=24$ variables in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gglasso.helper.basic_linalg import scale_array_by_diagonal\n",
    "\n",
    "n_comp = 8\n",
    "all_traf = list()\n",
    "\n",
    "# compute FPCA coefficients for each variable\n",
    "for j in range(n_var):\n",
    "    this_ds = samples[j]\n",
    "    fpca = FPCA(n_components=n_comp)\n",
    "    fpca.fit(this_ds)\n",
    "    _traf = fpca.transform(this_ds)\n",
    "    \n",
    "    # for second variable, permute fpca components in order to get off-diagonal correlation wrt first variable\n",
    "    if j==1:\n",
    "        _perm = np.random.permutation(n_comp)\n",
    "        _traf = _traf[:,_perm]\n",
    "        \n",
    "    all_traf.append(_traf)\n",
    "    \n",
    "fpca_samples = np.hstack(all_traf)\n",
    "print(\"(N,p) = \", fpca_samples.shape)\n",
    "\n",
    "# compute covariances\n",
    "S = np.cov(fpca_samples.T)\n",
    "# scale to correlations\n",
    "S = scale_array_by_diagonal(S)\n",
    "\n",
    "print(\"S has shape \", S.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87531acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot samples\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(fpca_samples, ax=ax, alpha=1, vmin=-10, vmax=10, cmap='coolwarm',cbar=True)\n",
    "ax.vlines([(j+1)*n_comp for j in range(n_var)], 0, n_samples, color='k', lw=4)\n",
    "\n",
    "# plot heatmap\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(S, ax=ax, cmap=\"coolwarm\", vmax=.1, vmin=-.1, alpha=1.)\n",
    "ax.hlines([(j+1)*n_comp for j in range(n_var)], 0, n_var*n_comp, color='k', lw=3)\n",
    "ax.vlines([(j+1)*n_comp for j in range(n_var)], 0, n_var*n_comp, color='k', lw=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
